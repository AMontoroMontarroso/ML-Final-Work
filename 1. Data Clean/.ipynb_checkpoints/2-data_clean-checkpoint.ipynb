{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "43de0fd2-4d3f-c80e-4f35-e3a89ce9d71f"
   },
   "source": [
    "# Detailed Data Cleaning/Visualization\n",
    "\n",
    "*A blog post about the final end-to-end solution (21st place) is available [here](http://alanpryorjr.com), and the source code is [on my github](https://github.com/apryor6/Kaggle-Competition-Santander)*\n",
    "\n",
    "*This is a Python version of a kernel I wrote in R for this dataset found [here](https://www.kaggle.com/apryor6/santander-product-recommendation/detailed-cleaning-visualization). There are some slight differences between how missing values are treated in Python and R, so the two kernels are not exactly the same, but I have tried to make them as similar as possible. This was done as a convenience to anybody who wanted to use my cleaned data as a starting point but prefers Python to R. It also is educational to compare how the same task can be accomplished in either language.*\n",
    "\n",
    "The goal of this competition is to predict which new Santander products, if any, a customer will purchase in the following month. Here, I will do some data cleaning, adjust some features, and do some visualization to get a sense of what features might be important predictors. I won't be building a predictive model in this kernel, but I hope this gives you some insight/ideas and gets you excited to build your own model.\n",
    "\n",
    "Let's get to it\n",
    "\n",
    "## First Glance\n",
    "Limit the number of rows read in to avoid memory crashes with the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "85ebf22f-2673-cf92-99f2-f0024d3d7983",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "a833c896-c0a7-86b1-dff7-cdf3325cebfb",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pablo/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2723: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/home/pablo/anaconda2/lib/python2.7/site-packages/pandas/core/generic.py:2572: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  locs = rs.choice(axis_length, size=n, replace=replace, p=weights)\n",
      "/home/pablo/anaconda2/lib/python2.7/site-packages/numpy/lib/function_base.py:3834: RuntimeWarning: Invalid value encountered in percentile\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ncodpers</th>\n",
       "      <th>indrel</th>\n",
       "      <th>indrel_1mes</th>\n",
       "      <th>tipodom</th>\n",
       "      <th>cod_prov</th>\n",
       "      <th>ind_actividad_cliente</th>\n",
       "      <th>renta</th>\n",
       "      <th>ind_ahor_fin_ult1</th>\n",
       "      <th>ind_aval_fin_ult1</th>\n",
       "      <th>ind_cco_fin_ult1</th>\n",
       "      <th>...</th>\n",
       "      <th>ind_hip_fin_ult1</th>\n",
       "      <th>ind_plan_fin_ult1</th>\n",
       "      <th>ind_pres_fin_ult1</th>\n",
       "      <th>ind_reca_fin_ult1</th>\n",
       "      <th>ind_tjcr_fin_ult1</th>\n",
       "      <th>ind_valo_fin_ult1</th>\n",
       "      <th>ind_viv_fin_ult1</th>\n",
       "      <th>ind_nomina_ult1</th>\n",
       "      <th>ind_nom_pens_ult1</th>\n",
       "      <th>ind_recibo_ult1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.200000e+04</td>\n",
       "      <td>11901.000000</td>\n",
       "      <td>11901.000000</td>\n",
       "      <td>11901.0</td>\n",
       "      <td>11848.000000</td>\n",
       "      <td>11901.000000</td>\n",
       "      <td>9.937000e+03</td>\n",
       "      <td>12000.000000</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>12000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>12000.000000</td>\n",
       "      <td>12000.000000</td>\n",
       "      <td>12000.000000</td>\n",
       "      <td>12000.000000</td>\n",
       "      <td>12000.000000</td>\n",
       "      <td>12000.00000</td>\n",
       "      <td>12000.000000</td>\n",
       "      <td>11970.000000</td>\n",
       "      <td>11970.000000</td>\n",
       "      <td>12000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.145364e+05</td>\n",
       "      <td>1.164692</td>\n",
       "      <td>1.000084</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.294058</td>\n",
       "      <td>0.523233</td>\n",
       "      <td>1.320240e+05</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.804083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006917</td>\n",
       "      <td>0.013583</td>\n",
       "      <td>0.003167</td>\n",
       "      <td>0.053167</td>\n",
       "      <td>0.052333</td>\n",
       "      <td>0.03125</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.058814</td>\n",
       "      <td>0.067753</td>\n",
       "      <td>0.148250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.385846e+05</td>\n",
       "      <td>4.014231</td>\n",
       "      <td>0.009167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.836071</td>\n",
       "      <td>0.499481</td>\n",
       "      <td>2.621525e+05</td>\n",
       "      <td>0.012909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.396921</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082882</td>\n",
       "      <td>0.115758</td>\n",
       "      <td>0.056186</td>\n",
       "      <td>0.224375</td>\n",
       "      <td>0.222708</td>\n",
       "      <td>0.17400</td>\n",
       "      <td>0.072838</td>\n",
       "      <td>0.235286</td>\n",
       "      <td>0.251332</td>\n",
       "      <td>0.355362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.592100e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.638440e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.328258e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.837550e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.178274e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.378771e+06</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.203474e+07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ncodpers        indrel   indrel_1mes  tipodom      cod_prov  \\\n",
       "count  1.200000e+04  11901.000000  11901.000000  11901.0  11848.000000   \n",
       "mean   8.145364e+05      1.164692      1.000084      1.0     26.294058   \n",
       "std    4.385846e+05      4.014231      0.009167      0.0     12.836071   \n",
       "min    1.592100e+04      1.000000      1.000000      1.0      1.000000   \n",
       "25%    3.328258e+05           NaN           NaN      NaN           NaN   \n",
       "50%    9.837550e+05           NaN           NaN      NaN           NaN   \n",
       "75%    1.178274e+06           NaN           NaN      NaN           NaN   \n",
       "max    1.378771e+06     99.000000      2.000000      1.0     52.000000   \n",
       "\n",
       "       ind_actividad_cliente         renta  ind_ahor_fin_ult1  \\\n",
       "count           11901.000000  9.937000e+03       12000.000000   \n",
       "mean                0.523233  1.320240e+05           0.000167   \n",
       "std                 0.499481  2.621525e+05           0.012909   \n",
       "min                 0.000000  8.638440e+03           0.000000   \n",
       "25%                      NaN           NaN           0.000000   \n",
       "50%                      NaN           NaN           0.000000   \n",
       "75%                      NaN           NaN           0.000000   \n",
       "max                 1.000000  2.203474e+07           1.000000   \n",
       "\n",
       "       ind_aval_fin_ult1  ind_cco_fin_ult1       ...         ind_hip_fin_ult1  \\\n",
       "count            12000.0      12000.000000       ...             12000.000000   \n",
       "mean                 0.0          0.804083       ...                 0.006917   \n",
       "std                  0.0          0.396921       ...                 0.082882   \n",
       "min                  0.0          0.000000       ...                 0.000000   \n",
       "25%                  0.0          1.000000       ...                 0.000000   \n",
       "50%                  0.0          1.000000       ...                 0.000000   \n",
       "75%                  0.0          1.000000       ...                 0.000000   \n",
       "max                  0.0          1.000000       ...                 1.000000   \n",
       "\n",
       "       ind_plan_fin_ult1  ind_pres_fin_ult1  ind_reca_fin_ult1  \\\n",
       "count       12000.000000       12000.000000       12000.000000   \n",
       "mean            0.013583           0.003167           0.053167   \n",
       "std             0.115758           0.056186           0.224375   \n",
       "min             0.000000           0.000000           0.000000   \n",
       "25%             0.000000           0.000000           0.000000   \n",
       "50%             0.000000           0.000000           0.000000   \n",
       "75%             0.000000           0.000000           0.000000   \n",
       "max             1.000000           1.000000           1.000000   \n",
       "\n",
       "       ind_tjcr_fin_ult1  ind_valo_fin_ult1  ind_viv_fin_ult1  \\\n",
       "count       12000.000000        12000.00000      12000.000000   \n",
       "mean            0.052333            0.03125          0.005333   \n",
       "std             0.222708            0.17400          0.072838   \n",
       "min             0.000000            0.00000          0.000000   \n",
       "25%             0.000000            0.00000          0.000000   \n",
       "50%             0.000000            0.00000          0.000000   \n",
       "75%             0.000000            0.00000          0.000000   \n",
       "max             1.000000            1.00000          1.000000   \n",
       "\n",
       "       ind_nomina_ult1  ind_nom_pens_ult1  ind_recibo_ult1  \n",
       "count     11970.000000       11970.000000     12000.000000  \n",
       "mean          0.058814           0.067753         0.148250  \n",
       "std           0.235286           0.251332         0.355362  \n",
       "min           0.000000           0.000000         0.000000  \n",
       "25%                NaN                NaN         0.000000  \n",
       "50%                NaN                NaN         0.000000  \n",
       "75%                NaN                NaN         0.000000  \n",
       "max           1.000000           1.000000         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limit_rows   = 500000\n",
    "df           = pd.read_csv(\"../Data/train_ver2.csv\",dtype={\"sexo\":str,\n",
    "                                                    \"ind_nuevo\":str,\n",
    "                                                    \"ult_fec_cli_1t\":str,\n",
    "                                                    \"indext\":str}, nrows=limit_rows)\n",
    "unique_ids   = pd.Series(df[\"ncodpers\"].unique())\n",
    "limit_people = 1.2e4\n",
    "unique_id    = unique_ids.sample(n=limit_people)\n",
    "df           = df[df.ncodpers.isin(unique_id)]\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8d1a3836-0310-6a6f-94fc-2a9c2a4984cc"
   },
   "source": [
    "We have a number of demographics for each individual as well as the products they currently own. To make a test set, I will separate the last month from this training data, and create a feature that indicates whether or not a product was newly purchased. First convert the dates. There's `fecha_dato`, the row-identifier date, and `fecha_alta`, the date that the customer joined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "9dfc376a-b836-94b4-03e3-bc3740b97aa8",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2015-01-28T00:00:00.000000000'], dtype='datetime64[ns]')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"fecha_dato\"] = pd.to_datetime(df[\"fecha_dato\"],format=\"%Y-%m-%d\")\n",
    "df[\"fecha_alta\"] = pd.to_datetime(df[\"fecha_alta\"],format=\"%Y-%m-%d\")\n",
    "df[\"fecha_dato\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5e439040-c7d7-1b7f-2954-ffb535d2bf64"
   },
   "source": [
    "I printed the values just to double check the dates were in standard Year-Month-Day format. I expect that customers will be more likely to buy products at certain months of the year (Christmas bonuses?), so let's add a month column. I don't think the month that they joined matters, so just do it for one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b5e8429d-a0f3-b5a5-81d6-7e524b0a660c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"month\"] = pd.DatetimeIndex(df[\"fecha_dato\"]).month\n",
    "df[\"age\"]   = pd.to_numeric(df[\"age\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bdb7e954-d855-fd00-613e-1452067a8c99"
   },
   "source": [
    "Are there any columns missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "7c2e1189-ac6b-d1bb-48a4-472c1328485d",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fecha_dato               False\n",
       "ncodpers                 False\n",
       "ind_empleado              True\n",
       "pais_residencia           True\n",
       "sexo                      True\n",
       "age                       True\n",
       "fecha_alta                True\n",
       "ind_nuevo                 True\n",
       "antiguedad               False\n",
       "indrel                    True\n",
       "ult_fec_cli_1t            True\n",
       "indrel_1mes               True\n",
       "tiprel_1mes               True\n",
       "indresi                   True\n",
       "indext                    True\n",
       "conyuemp                  True\n",
       "canal_entrada             True\n",
       "indfall                   True\n",
       "tipodom                   True\n",
       "cod_prov                  True\n",
       "nomprov                   True\n",
       "ind_actividad_cliente     True\n",
       "renta                     True\n",
       "segmento                  True\n",
       "ind_ahor_fin_ult1        False\n",
       "ind_aval_fin_ult1        False\n",
       "ind_cco_fin_ult1         False\n",
       "ind_cder_fin_ult1        False\n",
       "ind_cno_fin_ult1         False\n",
       "ind_ctju_fin_ult1        False\n",
       "ind_ctma_fin_ult1        False\n",
       "ind_ctop_fin_ult1        False\n",
       "ind_ctpp_fin_ult1        False\n",
       "ind_deco_fin_ult1        False\n",
       "ind_deme_fin_ult1        False\n",
       "ind_dela_fin_ult1        False\n",
       "ind_ecue_fin_ult1        False\n",
       "ind_fond_fin_ult1        False\n",
       "ind_hip_fin_ult1         False\n",
       "ind_plan_fin_ult1        False\n",
       "ind_pres_fin_ult1        False\n",
       "ind_reca_fin_ult1        False\n",
       "ind_tjcr_fin_ult1        False\n",
       "ind_valo_fin_ult1        False\n",
       "ind_viv_fin_ult1         False\n",
       "ind_nomina_ult1           True\n",
       "ind_nom_pens_ult1         True\n",
       "ind_recibo_ult1          False\n",
       "month                    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "87f2316f-9b93-13c8-7f22-a11eda6c7622"
   },
   "source": [
    "Definitely. Onto data cleaning.\n",
    "\n",
    "## Data Cleaning\n",
    "\n",
    "Going down the list, start with `age`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "d0484da4-b8f3-a514-c441-eef972179098",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with sns.plotting_context(\"notebook\",font_scale=1.5):\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.distplot(df[\"age\"].dropna(),\n",
    "                 bins=80,\n",
    "                 kde=False,\n",
    "                 color=\"tomato\")\n",
    "    sns.plt.title(\"Age Distribution\")\n",
    "    plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c7e2eaae-4bef-d74f-ff3f-50322caf8bd3"
   },
   "source": [
    "In addition to NA, there are people with very small and very high ages.\n",
    "It's also interesting that the distribution is bimodal. There are a large number of university aged students, and then another peak around middle-age. Let's separate the distribution and move the outliers to the mean of the closest one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "73e3143f-d51b-bd0a-a8cc-64178de70e4e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# ¿Realmente tiene sentido quitar los menores de 18 y mayores de 100? \n",
    "# Pueden ser individuos que tengan un comportamiento muy parecido \n",
    "# debido a sus edades extremas. Al centrar sus valores puede que se \n",
    "# pierda precision\n",
    "\"\"\"\n",
    "#df.loc[df.age < 18,\"age\"]  = df.loc[(df.age >= 18) & (df.age <= 30),\"age\"].mean(skipna=True)\n",
    "#df.loc[df.age > 100,\"age\"] = df.loc[(df.age >= 30) & (df.age <= 100),\"age\"].mean(skipna=True)\n",
    "df[\"age\"].fillna(df[\"age\"].mean(),inplace=True)\n",
    "df[\"age\"]                  = df[\"age\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "1d867605-f48a-7109-afa0-de92b2d8fbdd",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with sns.plotting_context(\"notebook\",font_scale=1.5):\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.distplot(df[\"age\"].dropna(),\n",
    "                 bins=80,\n",
    "                 kde=False,\n",
    "                 color=\"tomato\")\n",
    "    sns.plt.title(\"Age Distribution\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xlim((0,120))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6028f2ab-b7d5-920d-a313-e00776856f79"
   },
   "source": [
    "Looks better.  \n",
    "\n",
    "Next `ind_nuevo`, which indicates whether a customer is new or not. How many missing values are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "72710055-5dec-fafc-c712-27475eeb965b",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"ind_nuevo\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a15606ec-bf21-afd6-d5cc-20b7ac0ebc42"
   },
   "source": [
    "Let's see if we can fill in missing values by looking how many months of history these customers have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "e72879e7-8853-57da-5211-0bc07dc9baed",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "months_active = df.loc[df[\"ind_nuevo\"].isnull(),:].groupby(\"ncodpers\", sort=False).size()\n",
    "months_active.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2e52e713-8002-1ddc-feff-2785f7a97578"
   },
   "source": [
    "Looks like these are all new customers, so replace accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "672d6595-2ddc-3a34-48d8-c6f98fe3e0ef",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc[df[\"ind_nuevo\"].isnull(),\"ind_nuevo\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "07890c58-9e34-4d1a-e6b7-b63b3ab12943"
   },
   "source": [
    "Now, `antiguedad`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "f5597d19-ba99-e4d6-36f7-8463b8199ff6",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.antiguedad = pd.to_numeric(df.antiguedad,errors=\"coerce\")\n",
    "np.sum(df[\"antiguedad\"].isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "78e8d734-464b-9ecf-3314-9cd0a8f1f28e"
   },
   "source": [
    "That number again. Probably the same people that we just determined were new customers. Double check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "88314fe6-4eff-7d0b-8d43-e2c1ae315965",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     99\n",
       "unique     1\n",
       "top        1\n",
       "freq      99\n",
       "Name: ind_nuevo, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df[\"antiguedad\"].isnull(),\"ind_nuevo\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5f923230-78ca-a90b-09fa-650cbee30890"
   },
   "source": [
    "Yup, same people. Let's give them minimum seniority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "561ac875-a3c8-e843-caf7-aeafbc977185",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc[df.antiguedad.isnull(),\"antiguedad\"] = df.antiguedad.min()\n",
    "df.loc[df.antiguedad <0, \"antiguedad\"]      = 0 # Thanks @StephenSmith for bug-find"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "00eec8e6-c8c7-5d32-aa7d-43e536368bb1"
   },
   "source": [
    "Some entries don't have the date they joined the company. Just give them something in the middle of the pack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "55f39399-dbb7-3b13-5393-f6ad89d4fe24",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                   12000\n",
       "unique                   3039\n",
       "top       2011-11-30 00:00:00\n",
       "freq                      116\n",
       "first     1995-01-16 00:00:00\n",
       "last      2015-01-28 00:00:00\n",
       "Name: fecha_alta, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates=df.loc[:,\"fecha_alta\"].sort_values().reset_index()\n",
    "median_date = int(np.median(dates.index.values))\n",
    "df.loc[df.fecha_alta.isnull(),\"fecha_alta\"] = dates.loc[median_date,\"fecha_alta\"]\n",
    "df[\"fecha_alta\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bae7c9c5-a972-c397-4c1d-be0d06f7066e"
   },
   "source": [
    "Next is `indrel`, which indicates:\n",
    "\n",
    "> 1 (First/Primary), 99 (Primary customer during the month but not at the end of the month)\n",
    "\n",
    "This sounds like a promising feature. I'm not sure if primary status is something the customer chooses or the company assigns, but either way it seems intuitive that customers who are dropping down are likely to have different purchasing behaviors than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"indrel\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "9286511c-1f0d-5c7a-e762-6bad69180144",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0     11881\n",
       "99.0       20\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series([i for i in df.indrel]).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1f57156d-a8fa-6470-83b5-38b1684ca409"
   },
   "source": [
    "Fill in missing with the more common status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "4bd3465b-5eae-2743-5929-f5779909df2d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc[df.indrel.isnull(),\"indrel\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bf47c303-22a0-36b2-cd69-4598f6210e84"
   },
   "source": [
    "> tipodom\t- Addres type. 1, primary address\n",
    " cod_prov\t- Province code (customer's address)\n",
    "\n",
    "`tipodom` doesn't seem to be useful, and the province code is not needed because the name of the province exists in `nomprov`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "bfbcd9e1-6e22-d742-9daf-d05a471f056a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop([\"tipodom\",\"cod_prov\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b8f66021-233e-eb7b-10db-58a059df9306"
   },
   "source": [
    "Quick check back to see how we are doing on missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "96fc171a-6e3f-f6f9-93d0-c9f9e707d60b",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fecha_dato               False\n",
       "ncodpers                 False\n",
       "ind_empleado              True\n",
       "pais_residencia           True\n",
       "sexo                      True\n",
       "age                      False\n",
       "fecha_alta               False\n",
       "ind_nuevo                False\n",
       "antiguedad               False\n",
       "indrel                   False\n",
       "ult_fec_cli_1t            True\n",
       "indrel_1mes               True\n",
       "tiprel_1mes               True\n",
       "indresi                   True\n",
       "indext                    True\n",
       "conyuemp                  True\n",
       "canal_entrada             True\n",
       "indfall                   True\n",
       "nomprov                   True\n",
       "ind_actividad_cliente     True\n",
       "renta                     True\n",
       "segmento                  True\n",
       "ind_ahor_fin_ult1        False\n",
       "ind_aval_fin_ult1        False\n",
       "ind_cco_fin_ult1         False\n",
       "ind_cder_fin_ult1        False\n",
       "ind_cno_fin_ult1         False\n",
       "ind_ctju_fin_ult1        False\n",
       "ind_ctma_fin_ult1        False\n",
       "ind_ctop_fin_ult1        False\n",
       "ind_ctpp_fin_ult1        False\n",
       "ind_deco_fin_ult1        False\n",
       "ind_deme_fin_ult1        False\n",
       "ind_dela_fin_ult1        False\n",
       "ind_ecue_fin_ult1        False\n",
       "ind_fond_fin_ult1        False\n",
       "ind_hip_fin_ult1         False\n",
       "ind_plan_fin_ult1        False\n",
       "ind_pres_fin_ult1        False\n",
       "ind_reca_fin_ult1        False\n",
       "ind_tjcr_fin_ult1        False\n",
       "ind_valo_fin_ult1        False\n",
       "ind_viv_fin_ult1         False\n",
       "ind_nomina_ult1           True\n",
       "ind_nom_pens_ult1         True\n",
       "ind_recibo_ult1          False\n",
       "month                    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d85d2c58-b6cd-1928-a321-23467561c7d5"
   },
   "source": [
    "Getting closer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_cell_guid": "cc0707d4-cea8-174f-16b7-f8fd3f8b67b5",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df[\"ind_actividad_cliente\"].isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bd3325ce-c4c9-3c01-c8c1-900093f05bbf"
   },
   "source": [
    "By now you've probably noticed that this number keeps popping up. A handful of the entries are just bad, and should probably just be excluded from the model. But for now I will just clean/keep them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_cell_guid": "afa661ef-5c01-ef33-3ac0-a7b35ecf2e27",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc[df.ind_actividad_cliente.isnull(),\"ind_actividad_cliente\"] = \\\n",
    "df[\"ind_actividad_cliente\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "b0400709-8b1d-1440-b940-d27ab17c528b",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['VALENCIA', 'TOLEDO', 'SALAMANCA', 'BARCELONA', 'CACERES', 'ZAMORA',\n",
       "       'CUENCA', 'LUGO', 'AVILA', 'CORU\\xc3\\x91A, A', 'SEVILLA',\n",
       "       'ALICANTE', 'CORDOBA', 'MADRID', 'BIZKAIA', 'CADIZ', 'ZARAGOZA',\n",
       "       'CASTELLON', 'MALAGA', 'BURGOS', 'VALLADOLID', 'TARRAGONA',\n",
       "       'CANTABRIA', 'SEGOVIA', 'ASTURIAS', 'LERIDA', 'CIUDAD REAL',\n",
       "       'PONTEVEDRA', 'RIOJA, LA', 'GRANADA', nan, 'MURCIA', 'HUELVA',\n",
       "       'BADAJOZ', 'GUADALAJARA', 'PALMAS, LAS', 'ALBACETE', 'GIPUZKOA',\n",
       "       'GIRONA', 'JAEN', 'BALEARS, ILLES', 'SORIA', 'LEON', 'OURENSE',\n",
       "       'ALMERIA', 'HUESCA', 'ALAVA', 'PALENCIA', 'NAVARRA',\n",
       "       'SANTA CRUZ DE TENERIFE', 'TERUEL', 'MELILLA', 'CEUTA'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nomprov.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "568e9011-a39a-ff51-67d5-3a260588f636"
   },
   "source": [
    "There was an issue with the unicode character ñ in [A Coruña](https://en.wikipedia.org/wiki/A_Coruña). I'll manually fix it, but if anybody knows a better way to catch cases like this I would be very glad to hear it in the comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "0dbadbd2-76be-0789-f745-803f93585318",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc[df.nomprov==\"CORU\\xc3\\x91A, A\",\"nomprov\"] = \"CORUNA, A\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ca29776f-143b-d2e0-ef05-3e573e5af04b"
   },
   "source": [
    "There's some rows missing a city that I'll relabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_cell_guid": "f2b0b646-b74a-8f51-d754-40e4c58c9578",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc[df.nomprov.isnull(),\"nomprov\"] = \"UNKNOWN\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7acb976b-5e9a-51a6-dec2-422ef0b8d97d"
   },
   "source": [
    "Now for gross income, aka `renta`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_cell_guid": "9830d62e-2fd0-ae57-a616-2a58ef7c93e7",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2063"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.renta.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7f3938b5-695f-2bc6-0145-37c81ef75be4"
   },
   "source": [
    "Here is a feature that is missing a lot of values. Rather than just filling them in with a median, it's probably more accurate to break it down region by region. To that end, let's take a look at the median income by region, and in the spirit of the competition let's color it like the Spanish flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_cell_guid": "587bca44-b0ba-37a9-9b99-b715c690688d",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>nomprov</th>\n",
       "      <th>renta</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MedianIncome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CUENCA</td>\n",
       "      <td>55334.925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LERIDA</td>\n",
       "      <td>59210.310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CIUDAD REAL</td>\n",
       "      <td>61072.530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AVILA</td>\n",
       "      <td>61646.610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JAEN</td>\n",
       "      <td>62453.640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       nomprov        renta\n",
       "               MedianIncome\n",
       "0       CUENCA    55334.925\n",
       "1       LERIDA    59210.310\n",
       "2  CIUDAD REAL    61072.530\n",
       "3        AVILA    61646.610\n",
       "4         JAEN    62453.640"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.loc[df.renta.notnull(),:].groupby(\"nomprov\").agg([{\"Sum\":sum},{\"Mean\":mean}])\n",
    "incomes = df.loc[df.renta.notnull(),:].groupby(\"nomprov\").agg({\"renta\":{\"MedianIncome\":np.median}})\n",
    "incomes.sort_values(by=(\"renta\",\"MedianIncome\"),inplace=True)\n",
    "incomes.reset_index(inplace=True)\n",
    "incomes.nomprov = incomes.nomprov.astype(\"category\", categories=[i for i in df.nomprov.unique()],ordered=False)\n",
    "incomes.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_cell_guid": "fd49def1-8da1-2d6f-15b8-73eb2c44a237",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.YTick at 0x7f42e0717d90>,\n",
       "  <matplotlib.axis.YTick at 0x7f42e07365d0>,\n",
       "  <matplotlib.axis.YTick at 0x7f42e0698b10>,\n",
       "  <matplotlib.axis.YTick at 0x7f42e06a1ad0>,\n",
       "  <matplotlib.axis.YTick at 0x7f42e06b8090>],\n",
       " <a list of 5 Text yticklabel objects>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with sns.axes_style({\n",
    "        \"axes.facecolor\":   \"#ffc400\",\n",
    "        \"axes.grid\"     :    False,\n",
    "        \"figure.facecolor\": \"#c60b1e\"}):\n",
    "    h = sns.factorplot(data=incomes,\n",
    "                   x=\"nomprov\",\n",
    "                   y=(\"renta\",\"MedianIncome\"),\n",
    "                   order=(i for i in incomes.nomprov),\n",
    "                   size=6,\n",
    "                   aspect=1.5,\n",
    "                   scale=1.0,\n",
    "                   color=\"#c60b1e\",\n",
    "                   linestyles=\"None\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.tick_params(labelsize=16,labelcolor=\"#ffc400\")#\n",
    "plt.ylabel(\"Median Income\",size=32,color=\"#ffc400\")\n",
    "plt.xlabel(\"City\",size=32,color=\"#ffc400\")\n",
    "plt.title(\"Income Distribution by City\",size=40,color=\"#ffc400\")\n",
    "plt.ylim(0,180000)\n",
    "plt.yticks(range(0,180000,40000))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6edf053e-2c31-3f39-e870-62d0b4cd30ac"
   },
   "source": [
    "There's a lot of variation, so I think assigning missing incomes by providence is a good idea. First group the data by city, and reduce to get the median. This intermediate data frame is joined by the original city names to expand the aggregated median incomes, ordered so that there is a 1-to-1 mapping between the rows, and finally the missing values are replaced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_cell_guid": "6fbf3979-141d-b716-3ba7-830d4b845172",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "grouped        = df.groupby(\"nomprov\").agg({\"renta\":lambda x: x.median(skipna=True)}).reset_index()\n",
    "new_incomes    = pd.merge(df,grouped,how=\"inner\",on=\"nomprov\").loc[:, [\"nomprov\",\"renta_y\"]]\n",
    "new_incomes    = new_incomes.rename(columns={\"renta_y\":\"renta\"}).sort_values(\"renta\").sort_values(\"nomprov\")\n",
    "df.sort_values(\"nomprov\",inplace=True)\n",
    "df             = df.reset_index()\n",
    "new_incomes    = new_incomes.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_cell_guid": "62958334-bca1-73e0-871e-20f70bed4867",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df.loc[df.renta.isnull(),\"renta\"] = new_incomes.loc[df.renta.isnull(),\"renta\"].reset_index()\n",
    "df.loc[df.renta.isnull(),\"renta\"] = df.loc[df.renta.notnull(),\"renta\"].median()\n",
    "df.sort_values(by=\"fecha_dato\",inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c5a83406-42f3-f518-224c-33cb63052cf6"
   },
   "source": [
    "The next columns with missing data I'll look at are features, which are just a boolean indicator as to whether or not that product was owned that month. Starting with `ind_nomina_ult1`.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_cell_guid": "4f280171-c0f3-c98e-bb35-ef903a9d9564",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ind_nomina_ult1.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "cb5e1ac0-7de1-412d-f35c-72f20e2e8e7f"
   },
   "source": [
    "I could try to fill in missing values for products by looking at previous months, but since it's such a small number of values for now I'll take the cheap way out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_cell_guid": "2ab8cd9b-5ec4-4c99-4f84-c394b39790d8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc[df.ind_nomina_ult1.isnull(), \"ind_nomina_ult1\"] = 0\n",
    "df.loc[df.ind_nom_pens_ult1.isnull(), \"ind_nom_pens_ult1\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3ad7235d-0368-a84e-6b29-ce4323590eb8"
   },
   "source": [
    "There's also a bunch of character columns that contain empty strings. In R, these are kept as empty strings instead of NA like in pandas. I originally worked through the data with missing values first in R, so if you are wondering why I skipped some NA columns here that's why. I'll take care of them now. For the most part, entries with NA will be converted to an unknown category.  \n",
    "First I'll get only the columns with missing values. Then print the unique values to determine what I should fill in with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_cell_guid": "299fe28e-8844-ed3d-d558-30986db1ee60",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values for ind_empleado:\n",
      "['N' 'F' 'B' 'A' nan]\n",
      "\n",
      "Unique values for pais_residencia:\n",
      "['ES' 'DO' 'GB' nan 'MX' 'DE' 'BY' 'EC' 'PL' 'CO' 'BG' 'BE' 'BR' 'CU' 'CA'\n",
      " 'PY' 'IT' 'RO' 'CH' 'PE' 'LU' 'SE' 'FR' 'US' 'UY' 'AU' 'SA' 'MD' 'HR' 'AR']\n",
      "\n",
      "Unique values for sexo:\n",
      "['V' 'H' nan]\n",
      "\n",
      "Unique values for ult_fec_cli_1t:\n",
      "[nan '2015-07-27' '2015-07-07' '2015-07-09' '2015-07-17' '2015-07-15'\n",
      " '2015-07-01' '2015-07-30' '2015-07-02' '2015-07-13' '2015-07-23'\n",
      " '2015-07-06' '2015-07-16' '2015-07-14' '2015-07-21' '2015-07-03'\n",
      " '2015-07-28']\n",
      "\n",
      "Unique values for tiprel_1mes:\n",
      "['A' 'I' nan]\n",
      "\n",
      "Unique values for indresi:\n",
      "['S' 'N' nan]\n",
      "\n",
      "Unique values for indext:\n",
      "['N' 'S' nan]\n",
      "\n",
      "Unique values for conyuemp:\n",
      "[nan 'N' 'S']\n",
      "\n",
      "Unique values for canal_entrada:\n",
      "['007' 'KHE' 'KAT' 'KFC' 'KFA' 'KAW' 'KCI' 'KAR' 'KAG' 'KAS' 'KAZ' 'KCC'\n",
      " 'KHD' 'KAD' 'KHK' 'KAY' 'KBH' 'KHC' 'KBZ' '013' 'KAQ' 'KAA' 'KFD' 'KEH'\n",
      " 'KHF' 'KBO' 'KAC' 'KGY' 'KDZ' 'KEY' 'KDY' 'KDX' 'KFN' 'KBQ' 'KCB' 'KAE'\n",
      " 'KEJ' 'RED' 'KEW' 'KCH' 'KBV' 'KEZ' 'KBR' 'KBU' 'KHO' 'KAU' 'KCG' 'KEI'\n",
      " 'KBF' 'KCL' 'KCD' 'KBL' 'KCA' 'KAB' 'KHL' 'KDR' 'KAJ' 'KDT' 'KCM' nan\n",
      " 'KDC' 'KAP' 'KCS' 'KAF' 'KAL' 'KCK' 'KDU' 'KEN' 'KAH' 'K00' 'KEC' 'KEA'\n",
      " 'KDP' 'KFP' 'KFG' 'KAI' 'KFR' 'KAM' 'KFF' 'KES' 'KFK' 'KFH' 'KDE' 'KEF'\n",
      " 'KDG' 'KGX' 'KBY' 'KDM' 'KBB' 'KFL' 'KGV' 'KFJ' 'KHM']\n",
      "\n",
      "Unique values for indfall:\n",
      "['N' 'S' nan]\n",
      "\n",
      "Unique values for segmento:\n",
      "['02 - PARTICULARES' '03 - UNIVERSITARIO' '01 - TOP' nan]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "string_data = df.select_dtypes(include=[\"object\"])\n",
    "missing_columns = [col for col in string_data if string_data[col].isnull().any()]\n",
    "for col in missing_columns:\n",
    "    print(\"Unique values for {0}:\\n{1}\\n\".format(col,string_data[col].unique()))\n",
    "del string_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "17dd06a2-0c4e-49cd-21ef-2cc8235d1706"
   },
   "source": [
    "Okay, based on that and the definitions of each variable, I will fill the empty strings either with the most common value or create an unknown category based on what I think makes more sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_cell_guid": "c52777c3-06be-bf9f-0e33-3ae7e1b47d37",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc[df.indfall.isnull(),\"indfall\"] = \"N\"\n",
    "df.loc[df.tiprel_1mes.isnull(),\"tiprel_1mes\"] = \"A\"\n",
    "df.tiprel_1mes = df.tiprel_1mes.astype(\"category\")\n",
    "\n",
    "# As suggested by @StephenSmith\n",
    "map_dict = { 1.0  : \"1\",\n",
    "            \"1.0\" : \"1\",\n",
    "            \"1\"   : \"1\",\n",
    "            \"3.0\" : \"3\",\n",
    "            \"P\"   : \"P\",\n",
    "            3.0   : \"3\",\n",
    "            2.0   : \"2\",\n",
    "            \"3\"   : \"3\",\n",
    "            \"2.0\" : \"2\",\n",
    "            \"4.0\" : \"4\",\n",
    "            \"4\"   : \"4\",\n",
    "            \"2\"   : \"2\"}\n",
    "\n",
    "df.indrel_1mes.fillna(\"P\",inplace=True)\n",
    "df.indrel_1mes = df.indrel_1mes.apply(lambda x: map_dict.get(x,x))\n",
    "df.indrel_1mes = df.indrel_1mes.astype(\"category\")\n",
    "\n",
    "\n",
    "unknown_cols = [col for col in missing_columns if col not in [\"indfall\",\"tiprel_1mes\",\"indrel_1mes\"]]\n",
    "for col in unknown_cols:\n",
    "    df.loc[df[col].isnull(),col] = \"UNKNOWN\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1434f0ea-f1f6-8f61-bbf8-6cf299339fc3"
   },
   "source": [
    "Let's check back to see if we missed anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_cell_guid": "28ee02b3-7e9c-0a66-3541-211ccd9dc34f",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                    False\n",
       "fecha_dato               False\n",
       "ncodpers                 False\n",
       "ind_empleado             False\n",
       "pais_residencia          False\n",
       "sexo                     False\n",
       "age                      False\n",
       "fecha_alta               False\n",
       "ind_nuevo                False\n",
       "antiguedad               False\n",
       "indrel                   False\n",
       "ult_fec_cli_1t           False\n",
       "indrel_1mes              False\n",
       "tiprel_1mes              False\n",
       "indresi                  False\n",
       "indext                   False\n",
       "conyuemp                 False\n",
       "canal_entrada            False\n",
       "indfall                  False\n",
       "nomprov                  False\n",
       "ind_actividad_cliente    False\n",
       "renta                    False\n",
       "segmento                 False\n",
       "ind_ahor_fin_ult1        False\n",
       "ind_aval_fin_ult1        False\n",
       "ind_cco_fin_ult1         False\n",
       "ind_cder_fin_ult1        False\n",
       "ind_cno_fin_ult1         False\n",
       "ind_ctju_fin_ult1        False\n",
       "ind_ctma_fin_ult1        False\n",
       "ind_ctop_fin_ult1        False\n",
       "ind_ctpp_fin_ult1        False\n",
       "ind_deco_fin_ult1        False\n",
       "ind_deme_fin_ult1        False\n",
       "ind_dela_fin_ult1        False\n",
       "ind_ecue_fin_ult1        False\n",
       "ind_fond_fin_ult1        False\n",
       "ind_hip_fin_ult1         False\n",
       "ind_plan_fin_ult1        False\n",
       "ind_pres_fin_ult1        False\n",
       "ind_reca_fin_ult1        False\n",
       "ind_tjcr_fin_ult1        False\n",
       "ind_valo_fin_ult1        False\n",
       "ind_viv_fin_ult1         False\n",
       "ind_nomina_ult1          False\n",
       "ind_nom_pens_ult1        False\n",
       "ind_recibo_ult1          False\n",
       "month                    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "51cfa3e9-cdb6-a949-ef3c-7f282ccda69b"
   },
   "source": [
    "Convert the feature columns into integer values (you'll see why in a second), and we're done cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_cell_guid": "2785dd85-e477-c2ca-b726-03fa317e32c2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_cols = df.iloc[:1,].filter(regex=\"ind_+.*ult.*\").columns.values\n",
    "for col in feature_cols:\n",
    "    df[col] = df[col].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('../Data/train_ver2_clean2.csv')"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 3,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
